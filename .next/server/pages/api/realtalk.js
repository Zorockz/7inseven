"use strict";(()=>{var e={};e.id=881,e.ids=[881],e.modules={145:e=>{e.exports=require("next/dist/compiled/next-server/pages-api.runtime.prod.js")},2079:e=>{e.exports=import("openai")},6249:(e,t)=>{Object.defineProperty(t,"l",{enumerable:!0,get:function(){return function e(t,n){return n in t?t[n]:"then"in t&&"function"==typeof t.then?t.then(t=>e(t,n)):"function"==typeof t&&"default"===n?t:void 0}}})},7741:(e,t,n)=>{n.a(e,async(e,a)=>{try{n.r(t),n.d(t,{config:()=>c,default:()=>u,routeModule:()=>d});var r=n(1802),o=n(7153),s=n(6249),i=n(3969),l=e([i]);i=(l.then?(await l)():l)[0];let u=(0,s.l)(i,"default"),c=(0,s.l)(i,"config"),d=new r.PagesAPIRouteModule({definition:{kind:o.x.PAGES_API,page:"/api/realtalk",pathname:"/api/realtalk",bundlePath:"",filename:""},userland:i});a()}catch(e){a(e)}})},7153:(e,t)=>{var n;Object.defineProperty(t,"x",{enumerable:!0,get:function(){return n}}),function(e){e.PAGES="PAGES",e.PAGES_API="PAGES_API",e.APP_PAGE="APP_PAGE",e.APP_ROUTE="APP_ROUTE"}(n||(n={}))},1802:(e,t,n)=>{e.exports=n(145)},3969:(e,t,n)=>{n.a(e,async(e,a)=>{try{n.r(t),n.d(t,{default:()=>s});var r=n(2079),o=e([r]);r=(o.then?(await o)():o)[0],require("dotenv").config({path:"../../.env"});let i=new r.default({apiKey:process.env.OPENAI_API_KEY});async function s(e,t){if("POST"!==e.method)return t.status(405).json({message:"Method not allowed"});let{input:n,tone:a}=e.body;if(!n||!a)return t.status(400).json({message:"Missing input or tone."});let r=`
You're an emotionally honest advice expert.

A user is venting, asking for advice, or explaining a personal dilemma. Your job is to give them one piece of clear, real advice — no fluff, no disclaimers, no overexplaining. Your tone should match what they asked for: ${a}.

Speak like a real person. Avoid saying things like "As an AI..." or "I'm just a language model."

User’s message:
"${n}"

Your response:
`;try{let e=(await i.chat.completions.create({model:"gpt-3.5-turbo",messages:[{role:"system",content:"You are an emotionally honest advice expert."},{role:"user",content:r}],temperature:.9})).choices[0].message.content.trim();return t.status(200).json({reply:e})}catch(e){return console.error("OpenAI error:",e.message),t.status(500).json({message:"Failed to fetch response from GPT."})}}a()}catch(e){a(e)}})}};var t=require("../../webpack-api-runtime.js");t.C(e);var n=t(t.s=7741);module.exports=n})();